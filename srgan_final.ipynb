{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\malak\\anaconda3\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\malak\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\malak\\anaconda3\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\malak\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\malak\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\malak\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\malak\\anaconda3\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\malak\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\malak\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import RRDBNet_arch as arch\n",
    "\n",
    "# Define paths for uploaded and result images\n",
    "upload_folder = 'uploads/'\n",
    "result_folder = 'results/' # Path to save the super-resolution results\n",
    "os.makedirs(result_folder, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malak\\AppData\\Local\\Temp\\ipykernel_7712\\332094786.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path), strict=True)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Path to the model directory (adjust based on your path)\n",
    "models_dir = 'models'\n",
    "\n",
    "def load_model(model_name, model_dir, device):\n",
    "    model_path = os.path.join(model_dir, model_name)\n",
    "    model = arch.RRDBNet(3, 3, 64, 23, gc=32)  # Define the architecture\n",
    "    model.load_state_dict(torch.load(model_path), strict=True)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "# Load the model\n",
    "model_name = 'RRDB_ESRGAN_x4.pth'  # Use the ESRGAN model\n",
    "model = load_model(model_name, models_dir, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def super_resolution(path_img, device, model):\n",
    "    base = os.path.splitext(os.path.basename(path_img))[0]  # Get the base name of the image\n",
    "    img = cv2.imread(path_img)  # Load the low-resolution image\n",
    "    img = img * 1.0 / 255  # Normalize the image\n",
    "    img = torch.from_numpy(np.transpose(img[:, :, [2, 1, 0]], (2, 0, 1))).float()  # Convert to torch tensor\n",
    "    LR = img.unsqueeze(0).to(device)  # Add a batch dimension and move to the correct device (CPU/GPU)\n",
    "\n",
    "    # Perform super-resolution\n",
    "    with torch.no_grad():\n",
    "        result = model(LR).data.squeeze().float().cpu().clamp_(0, 1).numpy()\n",
    "    \n",
    "    # Rearrange channels and scale back to image format\n",
    "    result = np.transpose(result[[2, 1, 0], :, :], (1, 2, 0))\n",
    "    result = (result * 255.0).round()\n",
    "    \n",
    "    # Save the result image\n",
    "    result_path = os.path.join(result_folder, f'{base}_sr.png')\n",
    "    cv2.imwrite(result_path, result)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all images in the upload folder and perform super-resolution\n",
    "for img_file in os.listdir(upload_folder):\n",
    "    if img_file.endswith('.jpg'):  # Only process JPG images\n",
    "        img_path = os.path.join(upload_folder, img_file)  # Get the full path of the image\n",
    "        super_resolution(img_path, device, model)  # Apply super-resolution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
